{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nbaudis/.anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/nbaudis/.anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/nbaudis/.anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/nbaudis/.anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/nbaudis/.anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/nbaudis/.anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/nbaudis/.anaconda3/envs/ml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/nbaudis/.anaconda3/envs/ml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/nbaudis/.anaconda3/envs/ml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/nbaudis/.anaconda3/envs/ml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/nbaudis/.anaconda3/envs/ml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/nbaudis/.anaconda3/envs/ml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from scipy.fftpack import fft\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "# import tensorflow_addons as ta\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (45360, 512, 3)\n",
      "Shape of y_train: (45360,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of x_train: {x_train.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features with PyEEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyeeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-faf2bc774561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m fisher_info = np.apply_along_axis(pyeeg.fisher_info, axis=1, \n\u001b[0;32m----> 2\u001b[0;31m                                   arr=x_train, Tau=4, DE=10)\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/ml/lib/python3.7/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mbuff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mbuff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minarr_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/UZH/7_HS2020/PHY371/Exercises/Ex12/pyeeg.py\u001b[0m in \u001b[0;36mfisher_info\u001b[0;34m(X, Tau, DE, W)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mW\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                 \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m                 \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_uv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0mW\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/UZH/7_HS2020/PHY371/Exercises/Ex12/pyeeg.py\u001b[0m in \u001b[0;36membed_seq\u001b[0;34m(X, Tau, D)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mTau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                         \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mTau\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fisher_info = np.apply_along_axis(pyeeg.fisher_info, axis=1, \n",
    "                                  arr=x_train, Tau=4, DE=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too slow\n",
    "ap_entropy = np.apply_along_axis(pyeeg.ap_entropy, axis=1, \n",
    "                                 arr=x_train[:100], M=2, R=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45360, 24)\n"
     ]
    }
   ],
   "source": [
    "def extract_data(x):\n",
    "    # Generate training set with extracted features\n",
    "    # Takes long, save to numpy file afterwards\n",
    "    pfd = np.apply_along_axis(pyeeg.pfd, axis=1, arr=x)\n",
    "\n",
    "    hfd = np.apply_along_axis(pyeeg.hfd, axis=1, arr=x, Kmax=5)\n",
    "\n",
    "    hjorth = np.apply_along_axis(pyeeg.hjorth, axis=1, arr=x)\n",
    "    hjorth = hjorth.reshape(x.shape[0], 2 * x.shape[2])\n",
    "\n",
    "    hurst = np.apply_along_axis(pyeeg.hurst, axis=1, arr=x)\n",
    "    hurst = np.nan_to_num(hurst)\n",
    "\n",
    "    dfa = np.apply_along_axis(pyeeg.dfa, axis=1, arr=x)\n",
    "\n",
    "    spectral_entropy = np.apply_along_axis(pyeeg.spectral_entropy, axis=1, \n",
    "                                 arr=x, Band=[0.5,4,7,12,30,64], Fs=128)\n",
    "\n",
    "    std = np.apply_along_axis(np.std, axis=1, arr=x)\n",
    "    \n",
    "    x_feat = np.concatenate((dfa, hfd, hjorth, pfd, spectral_entropy, hurst, std), axis=1)\n",
    "\n",
    "x_train_feat = extract_training_data(x_train)\n",
    "np.save('data/x_train_feat', x_train_feat)\n",
    "print(x_train_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45360, 24)\n"
     ]
    }
   ],
   "source": [
    "x_train_feat = np.load('data/x_train_feat.npy')\n",
    "print(x_train_feat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate weights for training, since the classes are imbalanced\n",
    "class_weight = {}\n",
    "\n",
    "count_0, count_1, count_2 = np.bincount(y_train)\n",
    "total = count_0 + count_1 + count_2\n",
    "\n",
    "weight_0 = (1 / count_0) * total\n",
    "weight_1 = (1 / count_1) * total\n",
    "weight_2 = (1 / count_2) * total\n",
    "\n",
    "class_weight[0] = weight_0\n",
    "class_weight[1] = weight_1\n",
    "class_weight[2] = weight_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for validation\n",
    "x_train_feat, x_val_feat, y_train, y_val = train_test_split(x_train_feat, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    # keras.layers.Flatten(input_shape=(1, 18)),\n",
    "    keras.layers.Dense(2048, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    # keras.layers.Dense(128, activation='relu'),\n",
    "    # keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adam', \n",
    "                    loss='sparse_categorical_crossentropy', \n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    # keras.layers.Flatten(input_shape=(1, 18)),\n",
    "    keras.layers.Dense(512, activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(512, activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "#     keras.layers.Dense(128, activation='sigmoid'),\n",
    "#     keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adam', \n",
    "                    loss='sparse_categorical_crossentropy', \n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36288 samples, validate on 9072 samples\n",
      "Epoch 1/15\n",
      "36288/36288 [==============================] - 3s 93us/sample - loss: 2.4870 - acc: 0.6542 - val_loss: 0.6479 - val_acc: 0.7336\n",
      "Epoch 2/15\n",
      "36288/36288 [==============================] - 3s 92us/sample - loss: 2.3854 - acc: 0.6604 - val_loss: 0.8376 - val_acc: 0.5209\n",
      "Epoch 3/15\n",
      "36288/36288 [==============================] - 3s 93us/sample - loss: 2.3650 - acc: 0.6620 - val_loss: 0.6857 - val_acc: 0.6596\n",
      "Epoch 4/15\n",
      "36288/36288 [==============================] - 3s 94us/sample - loss: 2.3446 - acc: 0.6672 - val_loss: 0.7098 - val_acc: 0.6569\n",
      "Epoch 5/15\n",
      "36288/36288 [==============================] - 5s 136us/sample - loss: 2.3069 - acc: 0.6742 - val_loss: 0.6682 - val_acc: 0.7007\n",
      "Epoch 6/15\n",
      "36288/36288 [==============================] - 7s 190us/sample - loss: 2.2989 - acc: 0.6792 - val_loss: 0.6596 - val_acc: 0.7002\n",
      "Epoch 7/15\n",
      "36288/36288 [==============================] - 4s 113us/sample - loss: 2.2256 - acc: 0.7001 - val_loss: 0.5696 - val_acc: 0.7596\n",
      "Epoch 8/15\n",
      "36288/36288 [==============================] - 6s 154us/sample - loss: 2.0915 - acc: 0.7269 - val_loss: 0.5873 - val_acc: 0.7231\n",
      "Epoch 9/15\n",
      "36288/36288 [==============================] - 5s 140us/sample - loss: 1.7766 - acc: 0.7690 - val_loss: 0.4559 - val_acc: 0.8353\n",
      "Epoch 10/15\n",
      "36288/36288 [==============================] - 5s 138us/sample - loss: 1.7639 - acc: 0.7739 - val_loss: 0.6008 - val_acc: 0.7226\n",
      "Epoch 11/15\n",
      "36288/36288 [==============================] - 6s 156us/sample - loss: 1.5679 - acc: 0.7998 - val_loss: 0.3719 - val_acc: 0.8341\n",
      "Epoch 12/15\n",
      "36288/36288 [==============================] - 5s 142us/sample - loss: 1.5137 - acc: 0.8056 - val_loss: 0.4650 - val_acc: 0.7477\n",
      "Epoch 13/15\n",
      "36288/36288 [==============================] - 5s 142us/sample - loss: 1.5124 - acc: 0.8075 - val_loss: 0.3240 - val_acc: 0.8735\n",
      "Epoch 14/15\n",
      "36288/36288 [==============================] - 4s 120us/sample - loss: 1.5078 - acc: 0.8118 - val_loss: 0.4137 - val_acc: 0.7954\n",
      "Epoch 15/15\n",
      "36288/36288 [==============================] - 5s 148us/sample - loss: 1.4919 - acc: 0.8142 - val_loss: 0.3654 - val_acc: 0.8179\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_feat, y_train, class_weight=class_weight, epochs=15, validation_data=(x_val_feat, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on training data: 0.6943\n"
     ]
    }
   ],
   "source": [
    "train_f1 = f1_score(y_train, np.argmax(model.predict(x_train_feat), axis=1), average='macro')\n",
    "print(f'F1 score on training data: {train_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on validation data: 0.6916\n"
     ]
    }
   ],
   "source": [
    "val_f1 = f1_score(y_val, np.argmax(model.predict(x_val_feat), axis=1), average='macro')\n",
    "print(f'F1 score on validation data: {val_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = load_testing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19440, 24)\n"
     ]
    }
   ],
   "source": [
    "# Test set with extracted features\n",
    "x_test_feat = extract_data(x_test)\n",
    "np.save('data/x_test_feat', x_test_feat)\n",
    "print(x_test_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_feat = np.load('data/x_test_feat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_test_feat)\n",
    "generate_submission(y_test_pred, 'DeepNN_Pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv('submissions/DeepNN_Pred_F758.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id  y\n",
      "0          0  1\n",
      "1          1  1\n",
      "2          2  2\n",
      "3          3  1\n",
      "4          4  2\n",
      "...      ... ..\n",
      "19435  19435  0\n",
      "19436  19436  0\n",
      "19437  19437  0\n",
      "19438  19438  0\n",
      "19439  19439  0\n",
      "\n",
      "[19440 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id  y\n",
      "0          0  2\n",
      "1          1  2\n",
      "2          2  3\n",
      "3          3  2\n",
      "4          4  3\n",
      "...      ... ..\n",
      "19435  19435  1\n",
      "19436  19436  1\n",
      "19437  19437  1\n",
      "19438  19438  1\n",
      "19439  19439  1\n",
      "\n",
      "[19440 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('submissions/DeepNN_Pred_F758_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
